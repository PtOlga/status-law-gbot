---
title: Status Law Gbot
emoji: ğŸ’¬
colorFrom: yellow
colorTo: purple
sdk: gradio
sdk_version: 5.23.0
app_file: app.py
pinned: false
---

# Status Law Assistant

An intelligent chatbot based on Hugging Face and LangChain for legal consultations using information from the Status Law company website.

## ğŸ“ Description

Status Law Assistant is a smart chatbot that answers user questions about Status Law company's legal services. The bot uses RAG (Retrieval-Augmented Generation) technology to find relevant information in a knowledge base created from the official website content and generates responses using a language model.

## âœ¨ Features

- Automatic creation and updating of knowledge base from status.law website content
- Relevant information search for user queries
- Context-aware response generation
- Multi-language query support (responds in the language of the question)
- Customizable text generation parameters (temperature, token count, etc.)
- Model switching with fallback mechanism
- Fine-tuning capabilities based on chat history
- Multiple model support:
  - Llama 2 7B Chat: Meta's general-purpose model optimized for chat
  - Zephyr 7B: State-of-the-art model with strong performance
  - Mistral 7B Instruct v0.2: Advanced model with superior multilingual capabilities
  - XGLM 7.5B: Specialized model for cross-lingual generation with 30+ language support

## ğŸš€ Technologies

- **LangChain**: For query processing chains and knowledge base management
- **Hugging Face**: For language model access and application hosting
- **FAISS**: For efficient vector search
- **Gradio**: For user interface creation
- **BeautifulSoup**: For web page information extraction
- **PEFT**: For efficient fine-tuning using LoRA
- **SentencePiece**: For tokenization

## ğŸ—ï¸ Project Structure

```
status-law-gbot/
â”œâ”€â”€ app.py                 # Main application file with interface and request handling logic
â”œâ”€â”€ requirements.txt       # Project dependencies
â”œâ”€â”€ config/               # Configuration files
â”‚   â”œâ”€â”€ settings.py       # Application settings and model configurations
â”‚   â””â”€â”€ constants.py      # Constants and default values
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ analytics/        # Analytics module
â”‚   â”‚   â””â”€â”€ chat_analyzer.py
â”‚   â”œâ”€â”€ knowledge_base/   # Knowledge base management
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”œâ”€â”€ training/         # Model training module
â”‚   â”‚   â”œâ”€â”€ fine_tuner.py  # LoRA fine-tuning implementation
â”‚   â”‚   â””â”€â”€ model_manager.py  # Model switching and management
â”‚   â””â”€â”€ models/          # Model storage
â”‚       â””â”€â”€ fine_tuned/  # Fine-tuned model storage
â”œâ”€â”€ web/                 # Web interface components
â”‚   â””â”€â”€ training_interface.py
â””â”€â”€ data/               # Data storage
    â”œâ”€â”€ vector_store/   # FAISS vector storage
    â”‚   â”œâ”€â”€ index.faiss
    â”‚   â””â”€â”€ index.pkl
    â””â”€â”€ chat_history/   # Conversation logs
        â””â”€â”€ logs.json
```

## ğŸ’¾ Data Storage

### Vector Store
- `data/vector_store/index.faiss`: FAISS vector store for document embeddings
- `data/vector_store/index.pkl`: Metadata and configuration for the vector store

### Chat History
- `data/chat_history/logs.json`: JSON file containing chat history and metadata

### Models
- `src/models/fine_tuned/`: Directory for storing fine-tuned models
- `src/models/registry.json`: Model registry and configuration

## ğŸš€ Usage

The Status Law Assistant chatbot uses this structure to:
1. Store and retrieve document embeddings for context-aware responses
2. Maintain chat history for conversation continuity
3. Track user interactions and improve response quality
4. Fine-tune models based on conversation history
5. Provide automatic model fallback in case of API errors
6. Support multiple language models with easy switching

## ğŸ› ï¸ Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/status-law-gbot.git
cd status-law-gbot
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration, including HUGGINGFACE_TOKEN
```

4. Run the application:
```bash
python app.py
```

## ğŸ”§ Model Fine-tuning

To fine-tune the model on your chat history:

```python
from src.training.fine_tuner import finetune_from_chat_history

success, message = finetune_from_chat_history(epochs=3)
print(message)
```

The fine-tuning process uses LoRA (Low-Rank Adaptation) for efficient training with minimal resource requirements.

## ğŸ”„ Model Switching

The application supports multiple models with automatic fallback:

- Llama 2 7B Chat (default)
- Zephyr 7B
- Custom fine-tuned versions

Models can be switched dynamically through the interface or programmatically:

```python
from src.training.model_manager import switch_to_model

switch_to_model("llama-7b")  # or "zephyr-7b"
```

## ğŸ”— Related Links

- [Status Law Website](https://status.law)
- [Status Law Assistant on Hugging Face](https://huggingface.co/spaces/Rulga/status-law-assistant)

## ğŸ“ License

Private repository for Status Law Assistant usage only.
