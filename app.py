import gradio as gr
import os
from huggingface_hub import InferenceClient
from config.constants import DEFAULT_SYSTEM_MESSAGE
from config.settings import DEFAULT_MODEL, HF_TOKEN
from src.knowledge_base.vector_store import create_vector_store, load_vector_store

# –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å —Ç–æ–∫–µ–Ω–æ–º
client = InferenceClient(
    DEFAULT_MODEL,
    token=HF_TOKEN
)

# –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
context_store = {}

def get_context(message, conversation_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    vector_store = load_vector_store()
    if vector_store is None:
        return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∑–¥–∞–π—Ç–µ –µ—ë —Å–Ω–∞—á–∞–ª–∞."
    
    try:
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_docs = vector_store.similarity_search(message, k=3)
        context_text = "\n\n".join([f"–ò–∑ {doc.metadata.get('source', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}: {doc.page_content}" for doc in context_docs])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        context_store[conversation_id] = context_text
        
        return context_text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {str(e)}")
        return ""

def respond(
    message,
    history,
    conversation_id,
    system_message,
    max_tokens,
    temperature,
    top_p,
):
    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä, —Å–æ–∑–¥–∞–µ–º ID
    if not conversation_id:
        import uuid
        conversation_id = str(uuid.uuid4())
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    context = get_context(message, conversation_id)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ Gradio –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
    messages = [{"role": "system", "content": system_message}]
    if context:
        messages[0]["content"] += f"\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n{context}"
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç OpenAI
    for user_msg, assistant_msg in history:
        messages.extend([
            {"role": "user", "content": user_msg},
            {"role": "assistant", "content": assistant_msg}
        ])
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    messages.append({"role": "user", "content": message})
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ API –∏ —Å—Ç—Ä–∏–º–∏–º –æ—Ç–≤–µ—Ç
    response = ""
    last_token = ""
    sentence_end_chars = {'.', '!', '?', '\n'}
    
    try:
        for chunk in client.chat_completion(
            messages,
            max_tokens=max_tokens,
            stream=True,
            temperature=temperature,
            top_p=top_p,
        ):
            token = chunk.choices[0].delta.content
            if token:
                response += token
                last_token = token
                yield [(message, response)], conversation_id

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        if last_token and last_token[-1] not in sentence_end_chars:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É, –µ—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ
            response += "."
            yield [(message, response)], conversation_id

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        messages.append({"role": "assistant", "content": response})
        try:
            from src.knowledge_base.dataset import DatasetManager
            dataset = DatasetManager()
            success, msg = dataset.save_chat_history(conversation_id, messages)
            if not success:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞: {msg}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞: {str(e)}")
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")
        yield [(message, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.")], conversation_id

def build_kb():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
    try:
        success, message = create_vector_store()
        return message
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {str(e)}"

def load_vector_store():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    try:
        from src.knowledge_base.dataset import DatasetManager
        dataset = DatasetManager()
        success, store = dataset.download_vector_store()
        if success:
            return store
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {store}")
        return None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {str(e)}")
        return None

# –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
with gr.Blocks() as demo:
    gr.Markdown("# ü§ñ Status Law Assistant")
    
    conversation_id = gr.State(None)
    
    with gr.Row():
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                label="–ß–∞—Ç",
                bubble_full_width=False,
                avatar_images=["user.png", "assistant.png"]  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    label="–í–∞—à –≤–æ–ø—Ä–æ—Å",
                    placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å...",
                    scale=4
                )
                submit_btn = gr.Button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å", variant="primary")
        
        with gr.Column(scale=1):
            gr.Markdown("### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π")
            build_kb_btn = gr.Button("–°–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π", variant="primary")
            kb_status = gr.Textbox(label="–°—Ç–∞—Ç—É—Å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π", interactive=False)
            
            gr.Markdown("### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
            max_tokens = gr.Slider(
                minimum=1, 
                maximum=2048, 
                value=512, 
                step=1, 
                label="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞",
                info="–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ. –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –¥–ª–∏–Ω–Ω–µ–µ –æ—Ç–≤–µ—Ç"
            )
            temperature = gr.Slider(
                minimum=0.1, 
                maximum=2.0, 
                value=0.7, 
                step=0.1, 
                label="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
                info="–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å. –ù–∏–∂–µ –∑–Ω–∞—á–µ–Ω–∏–µ = –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ –æ—Ç–≤–µ—Ç—ã"
            )
            top_p = gr.Slider(
                minimum=0.1, 
                maximum=1.0, 
                value=0.95, 
                step=0.05, 
                label="Top-p",
                info="–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ. –ù–∏–∂–µ –∑–Ω–∞—á–µ–Ω–∏–µ = –±–æ–ª–µ–µ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"
            )
            
            clear_btn = gr.Button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞")

    def respond_and_clear(
        message,
        history,
        conversation_id,
        max_tokens,
        temperature,
        top_p,
    ):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é respond
        response_generator = respond(
            message,
            history,
            conversation_id,
            DEFAULT_SYSTEM_MESSAGE,
            max_tokens,
            temperature,
            top_p,
        )
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø–æ–ª—è –≤–≤–æ–¥–∞
        for response in response_generator:
            yield response[0], response[1], ""  # chatbot, conversation_id, –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è msg

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π
    msg.submit(
        respond_and_clear,
        [msg, chatbot, conversation_id, max_tokens, temperature, top_p],
        [chatbot, conversation_id, msg]  # –î–æ–±–∞–≤–ª—è–µ–º msg –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    )
    submit_btn.click(
        respond_and_clear,
        [msg, chatbot, conversation_id, max_tokens, temperature, top_p],
        [chatbot, conversation_id, msg]  # –î–æ–±–∞–≤–ª—è–µ–º msg –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    )
    build_kb_btn.click(build_kb, None, kb_status)
    clear_btn.click(lambda: ([], None), None, [chatbot, conversation_id])

# –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
    if not load_vector_store():
        print("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–π—Ç–µ –µ—ë —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å.")
    
    demo.launch()
